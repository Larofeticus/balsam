** INSTALLATION

# install virtualenv
https://pypi.python.org/pypi/virtualenv

# set up an installation directory
export BASEDIR=/path/to/installation

# set up virtual env
mkdir $BASEDIR
cd $BASEDIR
virtualenv balsam_env

. balsam_env/bin/activate

# install prerequisites
pip install django
pip install south
pip install pika

# install balsam_core
# (extract the tar file in some directory other than $BASEDIR)
tar xzf balsam_core.tgz
cd balsam_core
python setup.py install --prefix=$BASEDIR/balsam_env

cd $BASEDIR
django-admin.py startproject balsam_deploy


#cp settings.py $BASEDIR/balsam_deploy/balsam_deploy
# edit $BASEDIR/balsam_deploy/balsam_deploy/settings.py
# - set the database filename
# - add balsam_core and south to the INSTALLED_APPLICATIONS
# - add 'from argo_settings import *' at end

# edit argo_settings.py and change the following:
- in the DATABASES section, set the NAME field to the full path to an sqlite3 file, preferably in $BASEDIR/balsam_deploy
- set BALSAM_DEPLOYMENT_DIRECTORY to $BASEDIR/balsam_deploy
- set BALSAM_WORK_DIRECTORY. A work directory will be created here for each job, and the job will be run in this directory.
- set BALSAM_SCHEDULER_SUBMIT_EXE, BALSAM_SCHEDULER_STATUS_EXE appropriately
- set BALSAM_GLOBUS_URL_COPY_EXE, BALSAM_GRID_PROXY_INIT_EXE appropriately
- set BALSAM_ALLOWED_EXECUTABLE_DIRECTORY. Only executables from this directory will be executed.

cd balsam_deploy
python manage.py syncdb --noinput



** START BALSAM SERVICE
The service fetches jobs from the messages queues and adds them to the database, and updates the job status in the database periodically. It operates on a period defined by BALSAM_FETCH_DELAY in settings.py.
. balsam_env/bin/activate
cd $BASEDIR/balsam_deploy
python manage.py balsam_service


** START BALSAM DAEMON
The daemon queries the local database for jobs to be run and manages them over their lifetime. It operates on a period defined by BALSAM_EXECUTION_DELAY in settings.py.
. balsam_env/bin/activate
cd $BASEDIR/balsam_deploy
python manage.py balsam_daemon


** ADD TEST JOB TO MESSAGE QUEUE
. balsam_env/bin/activate
cd $BASEDIR/rabbitmq
./newjob testjob


** INTEGRATION POINTS
- in settings.py, BALSAM_SCHEDULER_SUBMIT_EXE, BALSAM_SCHEDULER_STATUS_EXE identify the qsub and qstat executables, respectively
- in settings.py, BALSAM_GLOBUS_URL_COPY_EXE, BALSAM_GRID_PROXY_INIT_EXE identify the globus-url-copy and grid-proxy-init executables, respectively
- balsam_env/lib/python2.6/site-packages/balsam_core/scheduler.py is where qsub and qstat are called
- balsam_env/lib/python2.6/site-packages/balsam_core/management/commands/balsam_service.py is where qstat output is parsed for updating job status
- the queue for job submission is hard-coded in scheduler.py


